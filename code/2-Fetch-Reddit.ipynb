{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit get-comment tool, covid-19 sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import datetime as dt\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "comment_url = 'https://api.pushshift.io/reddit/search/comment'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define subreddits, fields gathered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with different localities here\n",
    "subreddits = ['nyc', 'houston']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_fields = ['id','title', 'created_utc','num_comments','subreddit']\n",
    "comment_fields = ['link_id','body','created_utc', 'subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set key terms; Name data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch name (suffix to add to all saved data)\n",
    "prefix = '2019_nokeywords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search terms\n",
    "keywords = 'covid|quarantine|pandemic|coronavirus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time flags (search starts at t2 and goes back by 'span_days' find t1)\n",
    "# 86400 utc = 1 day\n",
    "\n",
    "# Start Time\n",
    "t2 = round(time.time()) # Now\n",
    "# t2 = '1557446400' #5/10/2019, 12 am\n",
    "\n",
    "# Search Span\n",
    "span_days = 80\n",
    "\n",
    "t1 = str(int(t2) - span_days*86400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get submissions\n",
    "submissions = pd.DataFrame(columns = submission_fields)\n",
    "df_list = []\n",
    "\n",
    "for subreddit in subreddits:\n",
    "    start_time = t2\n",
    "    res = requests.get(\n",
    "        sub_url,\n",
    "        params={\n",
    "            'subreddit' : subreddit,\n",
    "            'q' : keywords,\n",
    "            'fields': submission_fields,\n",
    "            'size' : 400,\n",
    "            'sort_type' : 'num_comments',\n",
    "            'sort' : 'desc',\n",
    "            'before': start_time,  \n",
    "            'after': t1,      \n",
    "        })\n",
    "    # Make sure we got a 2xx response\n",
    "    res.raise_for_status()\n",
    "\n",
    "    df = pd.DataFrame(res.json()['data'])\n",
    "    \n",
    "    # Filter out non-commented; could also set 'sort_type' parameter to get most commented\n",
    "    df = df[df['num_comments'] >0]\n",
    "    \n",
    "    df_list.append(df)\n",
    "\n",
    "start_time = df.created_utc.min()\n",
    "submissions = pd.concat(df_list, axis=0)\n",
    "submissions['date'] = [dt.date.fromtimestamp(x).isoformat() for x in submissions['created_utc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate id dictionary for cross-referencing submissions with comments\n",
    "link_ids = {sub: submissions[submissions[\"subreddit\"] == sub][\"id\"] for sub in subreddits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "1000\n",
      "<Response [200]>\n",
      "2000\n",
      "<Response [200]>\n",
      "3000\n",
      "<Response [200]>\n",
      "4000\n",
      "<Response [200]>\n",
      "5000\n",
      "<Response [200]>\n",
      "6000\n",
      "<Response [200]>\n",
      "7000\n",
      "<Response [200]>\n",
      "8000\n",
      "<Response [200]>\n",
      "9000\n",
      "<Response [200]>\n",
      "10000\n",
      "<Response [200]>\n",
      "11000\n",
      "<Response [200]>\n",
      "12000\n",
      "<Response [200]>\n",
      "13000\n",
      "<Response [200]>\n",
      "14000\n",
      "<Response [200]>\n",
      "15000\n",
      "<Response [200]>\n",
      "16000\n",
      "<Response [200]>\n",
      "17000\n",
      "<Response [200]>\n",
      "18000\n",
      "<Response [200]>\n",
      "19000\n",
      "<Response [200]>\n",
      "20000\n",
      "<Response [200]>\n",
      "21000\n",
      "<Response [200]>\n",
      "22000\n",
      "<Response [200]>\n",
      "23000\n",
      "<Response [200]>\n",
      "24000\n",
      "<Response [200]>\n",
      "25000\n",
      "<Response [200]>\n",
      "26000\n",
      "<Response [200]>\n",
      "27000\n",
      "<Response [200]>\n",
      "28000\n",
      "<Response [200]>\n",
      "29000\n",
      "<Response [200]>\n",
      "30000\n",
      "<Response [200]>\n",
      "31000\n",
      "<Response [200]>\n",
      "32000\n",
      "<Response [200]>\n",
      "33000\n",
      "<Response [200]>\n",
      "34000\n",
      "<Response [200]>\n",
      "35000\n",
      "<Response [200]>\n",
      "36000\n",
      "<Response [200]>\n",
      "37000\n",
      "<Response [200]>\n",
      "38000\n",
      "<Response [200]>\n",
      "39000\n",
      "<Response [200]>\n",
      "40000\n",
      "<Response [200]>\n",
      "41000\n",
      "<Response [200]>\n",
      "42000\n",
      "<Response [200]>\n",
      "43000\n",
      "<Response [200]>\n",
      "44000\n",
      "<Response [200]>\n",
      "45000\n",
      "<Response [200]>\n",
      "46000\n",
      "<Response [200]>\n",
      "47000\n",
      "<Response [200]>\n",
      "48000\n",
      "<Response [200]>\n",
      "49000\n",
      "<Response [200]>\n",
      "50000\n",
      "<Response [200]>\n",
      "51000\n",
      "<Response [200]>\n",
      "52000\n",
      "<Response [200]>\n",
      "53000\n",
      "<Response [200]>\n",
      "54000\n",
      "<Response [200]>\n",
      "55000\n",
      "<Response [200]>\n",
      "56000\n",
      "<Response [200]>\n",
      "57000\n",
      "<Response [200]>\n",
      "58000\n",
      "<Response [200]>\n",
      "58073\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "1000\n",
      "<Response [200]>\n",
      "2000\n",
      "<Response [200]>\n",
      "3000\n",
      "<Response [200]>\n",
      "4000\n",
      "<Response [200]>\n",
      "5000\n",
      "<Response [200]>\n",
      "6000\n",
      "<Response [200]>\n",
      "7000\n",
      "<Response [200]>\n",
      "8000\n",
      "<Response [200]>\n",
      "9000\n",
      "<Response [200]>\n",
      "10000\n",
      "<Response [200]>\n",
      "11000\n",
      "<Response [200]>\n",
      "12000\n",
      "<Response [200]>\n",
      "13000\n",
      "<Response [200]>\n",
      "14000\n",
      "<Response [200]>\n",
      "15000\n",
      "<Response [200]>\n",
      "16000\n",
      "<Response [200]>\n",
      "17000\n",
      "<Response [200]>\n",
      "18000\n",
      "<Response [200]>\n",
      "19000\n",
      "<Response [200]>\n",
      "20000\n",
      "<Response [200]>\n",
      "21000\n",
      "<Response [200]>\n",
      "22000\n",
      "<Response [200]>\n",
      "23000\n",
      "<Response [200]>\n",
      "24000\n",
      "<Response [200]>\n",
      "25000\n",
      "<Response [200]>\n",
      "26000\n",
      "<Response [200]>\n",
      "27000\n",
      "<Response [200]>\n",
      "28000\n",
      "<Response [200]>\n",
      "29000\n",
      "<Response [200]>\n",
      "30000\n",
      "<Response [200]>\n",
      "31000\n",
      "<Response [200]>\n",
      "32000\n",
      "<Response [200]>\n",
      "33000\n",
      "<Response [200]>\n",
      "34000\n",
      "<Response [200]>\n",
      "35000\n",
      "<Response [200]>\n",
      "36000\n",
      "<Response [200]>\n",
      "37000\n",
      "<Response [200]>\n",
      "38000\n",
      "<Response [200]>\n",
      "39000\n",
      "<Response [200]>\n",
      "40000\n",
      "<Response [200]>\n",
      "41000\n",
      "<Response [200]>\n",
      "42000\n",
      "<Response [200]>\n",
      "43000\n",
      "<Response [200]>\n",
      "44000\n",
      "<Response [200]>\n",
      "45000\n",
      "<Response [200]>\n",
      "45130\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# get comments\n",
    "df_list = []\n",
    "\n",
    "for subreddit in subreddits:\n",
    "    start_time = t2\n",
    "    c = 0\n",
    "    while c < submissions[submissions['subreddit'] == subreddit]['num_comments'].sum():\n",
    "        res = requests.get(\n",
    "            comment_url,\n",
    "            params={\n",
    "                'subreddit' : subreddit,\n",
    "                'fields': comment_fields,\n",
    "                'link_id' : (['t3_' + n for n in link_ids[subreddit]]),  #/comment?link_id : /submission?ids\n",
    "                'size' : 1000,\n",
    "                'before' : start_time,\n",
    "            })\n",
    "        # Make sure we got a 2xx response\n",
    "        res.raise_for_status()\n",
    "\n",
    "        # Don't parse data unless we got at least one post\n",
    "        if len(res.json()['data']) == 0:\n",
    "            break\n",
    "        \n",
    "        df = pd.DataFrame(res.json()['data'])\n",
    "\n",
    "        # raise counter by number of rows in df\n",
    "        c += df.shape[0]\n",
    "\n",
    "        print(f\"Fetched {c} comments from r/{subreddit}\")\n",
    "\n",
    "        df_list.append(df)\n",
    "        start_time = df['created_utc'].min()\n",
    "        \n",
    "comments = pd.concat(df_list, axis=0)\n",
    "comments['date'] = [dt.date.fromtimestamp(x).isoformat() for x in comments['created_utc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample/Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fewest posts we got from a subreddit\n",
    "smallest = comments['subreddit'].value_counts().min()\n",
    "\n",
    "# Pare every subreddit down to this number by random sampling\n",
    "comments_sampled = pd.concat([\n",
    "        comments[comments['subreddit'] == subreddit].sample(smallest, random_state=101)\n",
    "        for subreddit in subreddits\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nyc        45130\n",
       "houston    45130\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify we now have equal classes\n",
    "data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to local hard drive with prefix\n",
    "data.to_csv(f'./data/{prefix}_comments_sampled.csv', index=False)\n",
    "comments.to_csv(f'./data/{prefix}_comments_all.csv', index=False)\n",
    "submissions.to_csv(f'./data/{prefix}_submissions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
